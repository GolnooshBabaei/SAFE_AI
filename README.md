# SAFE_AI

To fulfill trustworthiness, AI methods have to be safe. A safe application of AI must
satisfy four basic key-principles, summarised as: sustainability, accuracy, fairness and
explainability. “Sustainability” means that AI methodologies have to be robust, both in
terms of data and computation. “Fairness” implies that AI methods should not discriminate
by age, ethnicity, gender or other population groups. The “Explainability” key-principle
requires that AI models are interpretable in terms of their drivers.

# Install
safe_ai package can be installed from either PyPI or conda-forge:

pip install shap
or
conda install -c conda-forge shap

# Citations
The algorithms and visualizations used in this package came primarily out of research in [Statistical laboratory](https://sites.google.com/unipv.it/statslab-pavia/home?authuser=0) at the University of Pavia. If you use safe_ai package in your research we would appreciate a citation to the appropriate paper(s):
* For the RGA measure introduced in "Sustainability and Robustness", you can read/cite [this paper](https://link.springer.com/article/10.1007/s11135-023-01613-y)
